{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Skeletons from Videos and Check the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted /home/samer/Desktop/Projects/mmaction2/data/Data 7_3.zip to /home/samer/Desktop/Projects/mmaction2/data\n"
     ]
    }
   ],
   "source": [
    "# Extract the zip file\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def extract_zip(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Extracted {zip_path} to {extract_to}\")\n",
    "\n",
    "# Paths\n",
    "zip_path = '/home/samer/Desktop/Projects/mmaction2/data/Data 7_3.zip'  # Update with the actual path to your ZIP file\n",
    "extract_to = '/home/samer/Desktop/Projects/mmaction2/data'  # Update with the desired extraction path\n",
    "\n",
    "# Extract the ZIP file\n",
    "extract_zip(zip_path, extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Initialize YOLOv8 Pose model\n",
    "model = YOLO('yolov8m-pose.pt')\n",
    "\n",
    "def draw_skeletons_yolo(frame, keypoints):\n",
    "    for point in keypoints:\n",
    "        x, y, conf = point\n",
    "        if conf > 0.5:  # Confidence threshold\n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
    "    return frame\n",
    "\n",
    "def visualize_raw_sample_yolo(action, sequence, input_dir, output_dir):\n",
    "    sequence_dir = os.path.join(input_dir, action, sequence)\n",
    "    video_path = os.path.join(sequence_dir, \"sequence_video.avi\")\n",
    "\n",
    "    print(f\"Checking for video at: {video_path}\")  # Debugging print statement\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Missing video for {sequence} in {action}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{action}_{sequence}_data73_annotated.avi\")\n",
    "    video_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_num = 0\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Perform pose detection\n",
    "        results = model(frame)\n",
    "        for result in results:\n",
    "            if result.keypoints is not None:\n",
    "                keypoints = result.keypoints.data[0].cpu().numpy()  # Move keypoints to CPU and convert to numpy\n",
    "                frame = draw_skeletons_yolo(frame, keypoints)\n",
    "\n",
    "        video_writer.write(frame)\n",
    "        frame_num += 1\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    print(f\"Raw annotated video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "action = 'Browsing'\n",
    "sequence = 'sequence_1'\n",
    "input_dir = '/home/samer/Desktop/Projects/mmaction2/data/Data 7_3'\n",
    "output_dir = '/home/samer/Desktop/Projects/mmaction2/Visualizations/RawVid_KP_Visualization_Data_7_3'\n",
    "visualize_raw_sample_yolo(action, sequence, input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract skeletons from videos and save the as npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "def extract_skeletons_from_videos_yolo(actions, input_dir, output_dir, use_normalized=True):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    model = YOLO('yolov8m-pose.pt')\n",
    "    \n",
    "    for action in actions:\n",
    "        action_dir = os.path.join(input_dir, action)\n",
    "        sequences = sorted(os.listdir(action_dir), key=lambda x: int(x.split('_')[1]))\n",
    "        \n",
    "        for sequence in sequences:\n",
    "            sequence_dir = os.path.join(action_dir, sequence)\n",
    "            video_path = os.path.join(sequence_dir, \"sequence_video.avi\")\n",
    "            \n",
    "            if not os.path.exists(video_path):\n",
    "                print(f\"Missing video for {sequence} in {action}\")\n",
    "                continue\n",
    "            \n",
    "            skeleton_dir = os.path.join(output_dir, action, sequence)\n",
    "            os.makedirs(skeleton_dir, exist_ok=True)\n",
    "            \n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_num = 0\n",
    "            \n",
    "            while cap.isOpened():\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "                \n",
    "                results = model(frame, stream=True)\n",
    "                for result in results:\n",
    "                    if result.keypoints is not None:\n",
    "                        keypoints = result.keypoints.xyn[0].cpu().numpy() if use_normalized else result.keypoints.xy[0].cpu().numpy()\n",
    "                        scores = result.keypoints.conf[0].cpu().numpy()  # Get the keypoint scores\n",
    "\n",
    "                        keypoint_with_scores = np.hstack((keypoints, scores[:, np.newaxis]))\n",
    "\n",
    "                        # Save keypoints and scores as npy file\n",
    "                        npy_path = os.path.join(skeleton_dir, f\"{frame_num}.npy\")\n",
    "                        np.save(npy_path, keypoint_with_scores)\n",
    "                \n",
    "                frame_num += 1\n",
    "            \n",
    "            cap.release()\n",
    "            print(f\"Processed {sequence} in {action}\")\n",
    "\n",
    "    print(\"Extraction completed for all actions and sequences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['Browsing', 'Pick_up', 'Place_in_Basket', 'Compare', 'Read_Labels',\n",
    "           'Talk_on_Phone', 'Check_List', 'Return_Items', 'Look_Around', 'Conceal_Item',\n",
    "           'Leaving_Quickly', 'Distracting_Behavior']\n",
    "\n",
    "input_dir = '/home/samer/Desktop/Projects/mmaction2/data/Data_7_3'\n",
    "output_dir = '/home/samer/Desktop/Projects/mmaction2/data/Skeletons_YOLO_Data 7_3'\n",
    "\n",
    "extract_skeletons_from_videos_yolo(actions, input_dir, output_dir, use_normalized=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the extracted numpy skeletons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This function checks if the collected npy sequences correctly represent the extracted keypoints from YOLO.\n",
    "* Visualize the keypoints of a random video in the dataset to ensure that everything is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def visualize_extracted_skeletons_yolo(action, sequence, input_video_dir, skeletons_dir, output_dir):\n",
    "    sequence_video_path = os.path.join(input_video_dir, action, sequence, \"sequence_video.avi\")\n",
    "    skeleton_sequence_dir = os.path.join(skeletons_dir, action, sequence)\n",
    "\n",
    "    if not os.path.exists(sequence_video_path):\n",
    "        print(f\"Missing video for {sequence} in {action}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(skeleton_sequence_dir):\n",
    "        print(f\"Missing skeleton data for {sequence} in {action}\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(sequence_video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{action}_{sequence}_skeleton_annotated.mp4\")\n",
    "    video_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_num = 0\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        npy_path = os.path.join(skeleton_sequence_dir, f\"{frame_num}.npy\")\n",
    "        if os.path.exists(npy_path):\n",
    "            keypoints = np.load(npy_path)\n",
    "            coords = keypoints[:, :2]\n",
    "            scores = keypoints[:, 2]\n",
    "            print(f\"Frame {frame_num} keypoints: {coords}, scores: {scores}\")  # Debug print\n",
    "\n",
    "            for (x, y), score in zip(coords, scores):\n",
    "                # Scale the coordinates to frame dimensions\n",
    "                x = int(x * frame_width)\n",
    "                y = int(y * frame_height)\n",
    "                if score > 0.5:  # Only draw keypoints with high confidence\n",
    "                    cv2.circle(frame, (x, y), 3, (219, 55, 156), -1)\n",
    "                    print(f\"Drawing keypoint at: {(x, y)}, score: {score}\")  # Debug print\n",
    "\n",
    "        video_writer.write(frame)\n",
    "        frame_num += 1\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    print(f\"Annotated video with skeletons saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 'Browsing'\n",
    "sequence = 'sequence_1'\n",
    "input_video_dir = '/home/samer/Desktop/Projects/mmaction2/data/Data_7_3'\n",
    "skeletons_dir = '/home/samer/Desktop/Projects/mmaction2/scripts/Skeletons_Visualization_Data_7_3'\n",
    "output_dir = '/home/samer/Desktop/Projects/mmaction2/scripts/Annotated_Videos'\n",
    "\n",
    "visualize_extracted_skeletons_yolo(action, sequence, input_video_dir, skeletons_dir, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
